{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jul1512/Software/miniconda3/envs/kongsr/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "###################################################################\n",
    "# This is an official PyTorch implementation for Target-specific\n",
    "# Generation of Molecules (TagMol)\n",
    "# Author: Junde Li, The Pennsylvania State University\n",
    "# Date: Aug 1, 2022\n",
    "###################################################################\n",
    "\n",
    "import os, time\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import pickle\n",
    "from rdkit import Chem\n",
    "from dataloader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Hyperparameters\n",
    "# --------------------------\n",
    "\n",
    "lr             = 1e-4\n",
    "beta1          = 0.0\n",
    "beta2          = 0.9\n",
    "batch_size     = 16\n",
    "max_epoch      = 400\n",
    "num_workers    = 2\n",
    "ligand_size    = 32\n",
    "x_dim         = 1024\n",
    "z_dim         = 128\n",
    "save_step      = 100\n",
    "\n",
    "name           = \"model/tagmol\"\n",
    "log_dir        = f\"{name}\"\n",
    "models_dir     = f\"{name}/saved_models\"\n",
    "device         = torch.device(\"cuda:0\")\n",
    "\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "os.makedirs(models_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PDBbindPLDataset(root_dir='data/pdbbind/tiny-set',\n",
    "                                    n_points=5000, \n",
    "                                    lig_size=32,\n",
    "                                    train=True,\n",
    "                                    transform=transforms.Compose([\n",
    "                                        Normalize(),\n",
    "                                        RandomRotateJitter(),\n",
    "                                        ToTensor()\n",
    "                                    ]))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8,\n",
    "                        shuffle=True)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_dataloader):\n",
    "    protein = sample_batched['protein']\n",
    "    atoms, bonds = sample_batched['ligand']\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Define Encoder Network\n",
    "# --------------------------\n",
    "\n",
    "class STN(nn.Module):\n",
    "    \"\"\"Spatial transformer network for alignment\"\"\"\n",
    "\n",
    "    def __init__(self, k):\n",
    "        super(STN, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(k, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, k * k)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.k = k\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        identity = Variable(torch.from_numpy(np.eye(self.k).flatten().astype(np.float32))).view(1, self.k * self.k).repeat(\n",
    "            batchsize, 1)\n",
    "        if x.is_cuda:\n",
    "            identity = identity.cuda()\n",
    "        x = x + identity\n",
    "        x = x.view(-1, self.k, self.k)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PointNetEncoder(nn.Module):\n",
    "    \"\"\"PointNet Encoder Network for protein embedding.\"\"\"\n",
    "\n",
    "    def __init__(self, x_dim, channel=4, feature_transform=False):\n",
    "        super(PointNetEncoder, self).__init__()\n",
    "        self.stn = STN(k=3)\n",
    "\n",
    "        self.conv1 = torch.nn.Conv1d(channel, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, x_dim, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(x_dim)\n",
    "        self.feature_transform = feature_transform\n",
    "        if self.feature_transform:\n",
    "            self.fstn = STN(k=64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, D, N = x.size()\n",
    "        trans = self.stn(x[:,:3,:]) # channel=3 only\n",
    "        x = x.transpose(2, 1)\n",
    "        if D > 3:\n",
    "            feature = x[:, :, 3:]\n",
    "            x = x[:, :, :3]\n",
    "        x = torch.bmm(x, trans) # shape=(B, N, 3)\n",
    "\n",
    "        if D > 3:\n",
    "            x = torch.cat([x, feature], dim=2)\n",
    "        x = x.transpose(2, 1) # shape=(B, D, N)\n",
    "        x = F.relu(self.bn1(self.conv1(x))) # shape=(B, 64, N)\n",
    "\n",
    "        if self.feature_transform:\n",
    "            trans_feat = self.fstn(x)\n",
    "            x = x.transpose(2, 1)\n",
    "            x = torch.bmm(x, trans_feat)\n",
    "            x = x.transpose(2, 1)\n",
    "        else:\n",
    "            trans_feat = None\n",
    "        \n",
    "        x = F.relu(self.bn2(self.conv2(x))) # shape=(B, 128, N)\n",
    "        x = self.bn3(self.conv3(x)) # shape=(B, x_dim, N)\n",
    "        # Aggregate point features by max pooling.\n",
    "        x = torch.max(x, 2, keepdim=True)[0] # shape=(B, x_dim)\n",
    "        x = x.view(-1, x_dim)\n",
    "        \n",
    "        return x, trans, trans_feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = PointNetEncoder(x_dim, channel=4, feature_transform=True)\n",
    "x, trans, trans_feat = self(protein.transpose(2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1024])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('kongsr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8d856909ca9685d9bf9012774e4c92e1590f564586ad7784e5945c8d33388486"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
